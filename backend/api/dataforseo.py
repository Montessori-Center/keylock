# api/dataforseo.py - –ü–û–õ–ù–û–°–¢–¨–Æ –ü–ï–†–ï–†–ê–ë–û–¢–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
import sys
from typing import Dict
from flask import Blueprint, request, jsonify
from config import Config
import pymysql
from typing import Dict
from datetime import datetime
from services.dataforseo_client import get_dataforseo_client, DataForSeoClient
from api.keywords import get_random_batch_color

dataforseo_bp = Blueprint('dataforseo', __name__)

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π flush –¥–ª—è –ª–æ–≥–æ–≤
def log_print(*args, **kwargs):
    print(*args, **kwargs)
    sys.stdout.flush()

def get_db_connection():
    """–°–æ–∑–¥–∞—ë—Ç –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
    return pymysql.connect(
        host=Config.DB_HOST,
        port=Config.DB_PORT,
        user=Config.DB_USER,
        password=Config.DB_PASSWORD,
        database=Config.DB_NAME,
        cursorclass=pymysql.cursors.DictCursor
    )

@dataforseo_bp.route('/test', methods=['GET', 'POST'])
def test_endpoint():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç endpoint"""
    try:
        log_print("üß™ TEST ENDPOINT –í–´–ó–í–ê–ù!")
        log_print(f"   Method: {request.method}")
        if request.method == 'POST':
            data = request.get_json()
            log_print(f"   Data: {data}")
        
        return jsonify({
            'success': True,
            'message': 'Test endpoint —Ä–∞–±–æ—Ç–∞–µ—Ç!',
            'method': request.method,
            'timestamp': str(datetime.utcnow())
        })
    except Exception as e:
        log_print(f"‚ùå Test endpoint error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@dataforseo_bp.route('/get-keywords-simple', methods=['POST'])
def get_keywords_simple():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ DataForSeo"""
    try:
        log_print("üß™ SIMPLE TEST –í–´–ó–í–ê–ù!")
        data = request.get_json()
        log_print(f"   –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {list(data.keys()) if data else 'None'}")
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—É
        import time
        time.sleep(1)
        
        return jsonify({
            'success': True,
            'message': '–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!',
            'received_keys': list(data.keys()) if data else [],
            'stats': {
                'total_results': 5,
                'added': 3,
                'updated': 2,
                'errors': 0,
                'cost': 0.00
            }
        })
    except Exception as e:
        log_print(f"‚ùå Simple test error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@dataforseo_bp.route('/get-keywords', methods=['POST'])
def get_new_keywords():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –≤—ã–¥–∞—á–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ DataForSeo"""
    connection = None
    
    log_print("=" * 50)
    log_print("üöÄ GET-KEYWORDS ENDPOINT –í–´–ó–í–ê–ù!")
    log_print("=" * 50)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'No data in request'}), 400
        
        seed_keywords = data.get('seed_keywords', [])
        ad_group_id = data.get('ad_group_id')
        
        log_print(f"üîë Seed keywords count: {len(seed_keywords)}")
        log_print(f"üè∑Ô∏è  Ad group ID: {ad_group_id}")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã API —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        location_code = data.get('location_code', 2804)
        language_code = data.get('language_code', 'ru')
        limit = data.get('limit', 700)
        search_partners = data.get('search_partners', False)
        include_seed_keyword = data.get('include_seed_keyword', True)
        sort_by = data.get('sort_by', 'relevance')
        date_from = data.get('date_from', '2024-01-01')
        date_to = data.get('date_to')
        
        if not seed_keywords:
            return jsonify({'success': False, 'error': 'No seed keywords provided'}), 400
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –≥—Ä—É–ø–ø—É –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        cursor.execute("SELECT * FROM ad_groups WHERE id = %s", (ad_group_id,))
        ad_group = cursor.fetchone()
        
        if not ad_group:
            return jsonify({'success': False, 'error': 'Ad group not found'}), 404
        
        campaign_id = ad_group['campaign_id']
        
        # –ó–∞–ø—Ä–æ—Å –∫ DataForSeo
        try:
            dataforseo_client = get_dataforseo_client()
            
            response = dataforseo_client.get_keywords_for_keywords(
                keywords=seed_keywords,
                location_code=location_code,
                language_code=language_code,
                search_partners=search_partners,
                sort_by=sort_by,
                limit=limit,
                include_seed_keyword=include_seed_keyword,
                date_from=date_from,
                date_to=date_to
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
            if not response.get('tasks'):
                return jsonify({
                    'success': False,
                    'error': 'No data received from DataForSeo'
                }), 500
            
            task = response['tasks'][0]
            if task.get('status_code') != 20000:
                error_msg = task.get('status_message', 'Unknown error')
                return jsonify({
                    'success': False,
                    'error': f"DataForSeo error: {error_msg}"
                }), 500
            
            request_cost = task.get('cost', 0.05)
            log_print(f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞: ${request_cost}")
            
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
            }), 400
        except Exception as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API error: {str(e)}'
            }), 500
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        try:
            keywords_data = dataforseo_client.parse_keywords_response(response)
            log_print(f"üìà –ü–æ–ª—É—á–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(keywords_data)}")
        except Exception as e:
            log_print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")
            keywords_data = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–≤–µ—Ç –¥–ª—è –Ω–æ–≤–æ–π –ø–∞—Ä—Ç–∏–∏
        batch_color = get_random_batch_color()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –ë–î
        added_count = 0
        updated_count = 0
        errors = []
        
        for kw_data in keywords_data:
            try:
                keyword_text = kw_data['keyword']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
                cursor.execute(
                    "SELECT * FROM keywords WHERE ad_group_id = %s AND keyword = %s",
                    (ad_group_id, keyword_text)
                )
                existing = cursor.fetchone()
                
                if existing:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ (—Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
                    update_query = """
                        UPDATE keywords SET 
                            avg_monthly_searches = %s,
                            competition = %s,
                            competition_percent = %s,
                            min_top_of_page_bid = %s,
                            max_top_of_page_bid = %s,
                            three_month_change = %s,
                            yearly_change = %s,
                            max_cpc = %s,
                            updated_at = NOW()
                        WHERE id = %s
                    """
                    
                    update_data = (
                        kw_data.get('avg_monthly_searches', 0),
                        kw_data.get('competition', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                        kw_data.get('competition_percent', 0),
                        kw_data.get('min_top_of_page_bid', 0),
                        kw_data.get('max_top_of_page_bid', 0),
                        kw_data.get('three_month_change'),
                        kw_data.get('yearly_change'),
                        kw_data.get('cpc', existing['max_cpc']),
                        existing['id']
                    )
                    
                    cursor.execute(update_query, update_data)
                    updated_count += 1
                else:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ
                    insert_query = """
                        INSERT INTO keywords (
                            campaign_id, ad_group_id, keyword, criterion_type, status,
                            avg_monthly_searches, competition, competition_percent,
                            min_top_of_page_bid, max_top_of_page_bid, three_month_change,
                            yearly_change, max_cpc, intent_type, is_new, batch_color,
                            has_ads, has_school_sites, has_google_maps, has_our_site
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """
                    
                    insert_data = (
                        campaign_id,
                        ad_group_id,
                        keyword_text,
                        'Phrase',
                        'Enabled',
                        kw_data.get('avg_monthly_searches', 0),
                        kw_data.get('competition', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                        kw_data.get('competition_percent', 0),
                        kw_data.get('min_top_of_page_bid', 0),
                        kw_data.get('max_top_of_page_bid', 0),
                        kw_data.get('three_month_change'),
                        kw_data.get('yearly_change'),
                        kw_data.get('cpc', 3.61),
                        '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π',  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ —á–µ—Ä–µ–∑ SERP
                        True,  # is_new
                        batch_color,  # batch_color
                        False,  # has_ads - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        False,  # has_school_sites - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        False,  # has_google_maps - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        False   # has_our_site - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    )
                    
                    cursor.execute(insert_query, insert_data)
                    added_count += 1
                    
            except Exception as e:
                errors.append(f"Error processing '{kw_data.get('keyword', 'unknown')}': {str(e)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        connection.commit()
        
        result = {
            'success': True,
            'message': f'–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(keywords_data)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤. –î–æ–±–∞–≤–ª–µ–Ω–æ: {added_count}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_count}',
            'stats': {
                'total_results': len(keywords_data),
                'added': added_count,
                'updated': updated_count,
                'errors': len(errors),
                'cost': request_cost
            },
            'cost': request_cost
        }
        
        if errors:
            result['errors'] = errors[:10]
        
        return jsonify(result)
        
    except Exception as e:
        if connection:
            connection.rollback()
        log_print(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()

@dataforseo_bp.route('/apply-serp', methods=['POST'])
def apply_serp_analysis():
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ SERP –∞–Ω–∞–ª–∏–∑–∞ –∫ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    connection = None
    try:
        data = request.json
        keyword_ids = data.get('keyword_ids', [])
        
        if not keyword_ids:
            return jsonify({'success': False, 'error': 'No keywords selected'}), 400
        
        log_print(f"üöÄ –ó–∞–ø—É—Å–∫ SERP –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {len(keyword_ids)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
        log_print(f"üìç –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: location={data.get('location_code')}, language={data.get('language_code')}")
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å campaign_id
        placeholders = ','.join(['%s'] * len(keyword_ids))
        cursor.execute(f"""
            SELECT k.id, k.keyword, k.campaign_id 
            FROM keywords k
            WHERE k.id IN ({placeholders})
        """, keyword_ids)
        keywords_data = cursor.fetchall()
        
        if not keywords_data:
            return jsonify({'success': False, 'error': 'Keywords not found'}), 404
        
        # –ü–æ–ª—É—á–∞–µ–º DataForSeo –∫–ª–∏–µ–Ω—Ç
        try:
            dataforseo_client = get_dataforseo_client()
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
            }), 400
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã SERP –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ frontend
        serp_params = {
            'location_code': data.get('location_code', 2804),
            'language_code': data.get('language_code', 'ru'),
            'device': data.get('device', 'desktop'),
            'os': data.get('os', 'windows'),
            'depth': data.get('depth', 100),
            'calculate_rectangles': data.get('calculate_rectangles', False),
            'browser_screen_width': data.get('browser_screen_width', 1920),
            'browser_screen_height': data.get('browser_screen_height', 1080),
            'se_domain': data.get('se_domain', 'google.com.ua')
        }
        
        log_print(f"üìã SERP –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {serp_params}")
        
        updated_count = 0
        errors = []
        total_cost = 0
        results_summary = {
            'with_ads': 0,
            'with_maps': 0,
            'with_our_site': 0,
            'with_school_sites': 0,
            'commercial_intent': 0
        }
        
        for kw in keywords_data:
            try:
                log_print(f"üîç SERP –∞–Ω–∞–ª–∏–∑ –¥–ª—è: '{kw['keyword']}'")
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º SERP –∑–∞–ø—Ä–æ—Å
                serp_response = dataforseo_client.get_serp(
                    keyword=kw['keyword'],
                    **serp_params
                )
                
                # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                serp_data = parse_serp_response(
                    serp_response, 
                    kw['campaign_id'], 
                    connection,
                    keyword_id=kw['id'],
                    keyword_text=kw['keyword']
                )
                
                if serp_data:
                    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
                    cursor.execute("""
                        UPDATE keywords 
                        SET 
                            has_ads = %s,
                            has_school_sites = %s,
                            has_google_maps = %s,
                            has_our_site = %s,
                            intent_type = %s,
                            updated_at = NOW()
                        WHERE id = %s
                    """, (
                        serp_data['has_ads'],
                        serp_data['has_school_sites'],
                        serp_data['has_google_maps'],
                        serp_data['has_our_site'],
                        serp_data['intent_type'],
                        kw['id']
                    ))
                    
                    updated_count += 1
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    if serp_data['has_ads']:
                        results_summary['with_ads'] += 1
                    if serp_data['has_google_maps']:
                        results_summary['with_maps'] += 1
                    if serp_data['has_our_site']:
                        results_summary['with_our_site'] += 1
                    if serp_data['has_school_sites']:
                        results_summary['with_school_sites'] += 1
                    if serp_data['intent_type'] == '–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π':
                        results_summary['commercial_intent'] += 1
                    
                    # –°—á–∏—Ç–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
                    if serp_response.get('tasks'):
                        task_cost = serp_response['tasks'][0].get('cost', 0.003)
                        total_cost += task_cost
                    
                    log_print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: {kw['keyword']}")
                    log_print(f"   - –†–µ–∫–ª–∞–º–∞: {serp_data['has_ads']}")
                    log_print(f"   - –ö–∞—Ä—Ç—ã: {serp_data['has_google_maps']}")
                    log_print(f"   - –ù–∞—à —Å–∞–π—Ç: {serp_data['has_our_site']}")
                    log_print(f"   - –°–∞–π—Ç—ã —à–∫–æ–ª: {serp_data['has_school_sites']}")
                    log_print(f"   - –ò–Ω—Ç–µ–Ω—Ç: {serp_data['intent_type']}")
                else:
                    errors.append(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è '{kw['keyword']}'")
                    log_print(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è: {kw['keyword']}")
                    
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –¥–ª—è '{kw['keyword']}': {str(e)}"
                log_print(f"‚ùå {error_msg}")
                errors.append(error_msg)
        
        connection.commit()
        cursor.close()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
        success_message = f"""
        SERP –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {updated_count} –∏–∑ {len(keywords_data)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        
        üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:
        ‚Ä¢ –° —Ä–µ–∫–ª–∞–º–æ–π: {results_summary['with_ads']} ({results_summary['with_ads']*100//max(updated_count,1)}%)
        ‚Ä¢ –° –∫–∞—Ä—Ç–∞–º–∏: {results_summary['with_maps']} ({results_summary['with_maps']*100//max(updated_count,1)}%)
        ‚Ä¢ –° –Ω–∞—à–∏–º —Å–∞–π—Ç–æ–º: {results_summary['with_our_site']} ({results_summary['with_our_site']*100//max(updated_count,1)}%)
        ‚Ä¢ –° —Å–∞–π—Ç–∞–º–∏ —à–∫–æ–ª: {results_summary['with_school_sites']} ({results_summary['with_school_sites']*100//max(updated_count,1)}%)
        ‚Ä¢ –ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ–Ω—Ç: {results_summary['commercial_intent']} ({results_summary['commercial_intent']*100//max(updated_count,1)}%)
        
        üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å: ${total_cost:.4f}
        """.strip()
        
        log_print("=" * 50)
        log_print(success_message)
        log_print("=" * 50)
        
        return jsonify({
            'success': True,
            'message': success_message,
            'stats': {
                'total': len(keywords_data),
                'updated': updated_count,
                'errors': len(errors),
                'summary': results_summary
            },
            'errors': errors[:10] if errors else [],
            'cost': round(total_cost, 4)
        })
        
    except Exception as e:
        if connection:
            connection.rollback()
        log_print(f"üí• SERP analysis error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()
            
@dataforseo_bp.route('/serp-logs', methods=['GET'])
def get_serp_logs():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö SERP –∞–Ω–∞–ª–∏–∑–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    connection = None
    try:
        limit = request.args.get('limit', 10, type=int)
        keyword_id = request.args.get('keyword_id', None, type=int)
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        if keyword_id:
            # –õ–æ–≥–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            cursor.execute("""
                SELECT * FROM serp_logs 
                WHERE keyword_id = %s 
                ORDER BY created_at DESC 
                LIMIT %s
            """, (keyword_id, limit))
        else:
            # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏
            cursor.execute("""
                SELECT * FROM serp_logs 
                ORDER BY created_at DESC 
                LIMIT %s
            """, (limit,))
        
        logs = cursor.fetchall()
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        formatted_logs = []
        for log in logs:
            formatted_log = {
                'id': log['id'],
                'keyword': log['keyword_text'],
                'created_at': log['created_at'].isoformat() if log['created_at'] else None,
                'summary': {
                    'total_items': log['total_items'],
                    'organic': log['organic_count'],
                    'paid': log['paid_count'],
                    'maps': log['maps_count']
                },
                'flags': {
                    'has_ads': bool(log['has_ads']),
                    'has_maps': bool(log['has_maps']),
                    'has_our_site': bool(log['has_our_site']),
                    'has_school_sites': bool(log['has_school_sites'])
                },
                'intent': log['intent_type'],
                'school_percentage': float(log['school_percentage']) if log['school_percentage'] else 0,
                'cost': float(log['cost']) if log['cost'] else 0,
                'raw_response': json.loads(log['raw_response']) if log['raw_response'] else {},
                'parsed_items': json.loads(log['parsed_items']) if log['parsed_items'] else {}
            }
            formatted_logs.append(formatted_log)
        
        cursor.close()
        
        return jsonify({
            'success': True,
            'count': len(formatted_logs),
            'logs': formatted_logs
        })
        
    except Exception as e:
        log_print(f"‚ùå Error getting SERP logs: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()


@dataforseo_bp.route('/serp-logs/<int:log_id>', methods=['GET'])
def get_serp_log_details(log_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º SERP –∞–Ω–∞–ª–∏–∑–µ"""
    connection = None
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        
        cursor.execute("SELECT * FROM serp_logs WHERE id = %s", (log_id,))
        log = cursor.fetchone()
        
        if not log:
            return jsonify({'success': False, 'error': 'Log not found'}), 404
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä
        parsed_items = json.loads(log['parsed_items']) if log['parsed_items'] else {}
        
        detailed_report = {
            'id': log['id'],
            'keyword': log['keyword_text'],
            'created_at': log['created_at'].isoformat() if log['created_at'] else None,
            'parameters': {
                'location_code': log['location_code'],
                'language_code': log['language_code'],
                'device': log['device'],
                'depth': log['depth']
            },
            'summary': {
                'total_items': log['total_items'],
                'organic_count': log['organic_count'],
                'paid_count': log['paid_count'],
                'maps_count': log['maps_count']
            },
            'analysis_result': {
                'has_ads': bool(log['has_ads']),
                'has_maps': bool(log['has_maps']),
                'has_our_site': bool(log['has_our_site']),
                'has_school_sites': bool(log['has_school_sites']),
                'intent_type': log['intent_type'],
                'school_percentage': float(log['school_percentage']) if log['school_percentage'] else 0
            },
            'cost': float(log['cost']) if log['cost'] else 0,
            'organic_results': parsed_items.get('organic', []),
            'paid_results': parsed_items.get('paid', []),
            'all_items': parsed_items.get('all_items', [])
        }
        
        cursor.close()
        
        return jsonify({
            'success': True,
            'report': detailed_report
        })
        
    except Exception as e:
        log_print(f"‚ùå Error getting SERP log details: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()

@dataforseo_bp.route('/test-connection', methods=['POST'])
def test_dataforseo_connection():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ DataForSeo API"""
    try:
        data = request.json
        temp_client = DataForSeoClient(data['login'], data['password'])
        status = temp_client.get_status()
        
        if status.get('tasks') and status['tasks'][0].get('result'):
            balance = status['tasks'][0]['result'][0].get('money', {}).get('balance', 0)
            return jsonify({
                'success': True, 
                'message': f'API —Ä–∞–±–æ—Ç–∞–µ—Ç. –ë–∞–ª–∞–Ω—Å: ${balance}'
            })
        else:
            return jsonify({'success': False, 'message': '–ù–µ–≤–µ—Ä–Ω—ã–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'})
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ API: {str(e)}'})
        
@dataforseo_bp.route('/check-serp-cost', methods=['POST'])
def check_serp_cost():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ SERP –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º"""
    try:
        data = request.json
        keyword_ids = data.get('keyword_ids', [])
        depth = data.get('depth', 100)
        
        # –†–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        base_cost = 0.003  # $0.003 –∑–∞ SERP regular –¥–æ 100 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≥–ª—É–±–∏–Ω—ã
        if depth <= 20:
            depth_multiplier = 1
        elif depth <= 50:
            depth_multiplier = 1.5
        elif depth <= 100:
            depth_multiplier = 2
        else:
            depth_multiplier = 3  # –¥–ª—è depth > 100
        
        estimated_cost = len(keyword_ids) * base_cost * depth_multiplier
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞
        try:
            dataforseo_client = get_dataforseo_client()
            status = dataforseo_client.get_status()
            
            current_balance = 0
            if status.get('tasks') and status['tasks'][0].get('result'):
                current_balance = status['tasks'][0]['result'][0].get('money', {}).get('balance', 0)
            
            can_proceed = current_balance >= estimated_cost
            
            return jsonify({
                'success': True,
                'estimated_cost': round(estimated_cost, 4),
                'current_balance': round(current_balance, 2),
                'can_proceed': can_proceed,
                'keywords_count': len(keyword_ids),
                'depth': depth,
                'message': f"–ê–Ω–∞–ª–∏–∑ {len(keyword_ids)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ ${estimated_cost:.4f}"
            })
            
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–ª–∞–Ω—Å, –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
            return jsonify({
                'success': True,
                'estimated_cost': round(estimated_cost, 4),
                'current_balance': None,
                'can_proceed': True,
                'keywords_count': len(keyword_ids),
                'depth': depth,
                'message': f"–ê–Ω–∞–ª–∏–∑ {len(keyword_ids)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ ${estimated_cost:.4f}",
                'warning': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–ª–∞–Ω—Å'
            })
            
    except Exception as e:
        log_print(f"‚ùå Error checking SERP cost: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@dataforseo_bp.route('/check-balance', methods=['GET'])
def check_balance():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∏ —Å—Ç–∞—Ç—É—Å–∞ –∞–∫–∫–∞—É–Ω—Ç–∞ DataForSeo"""
    try:
        dataforseo_client = get_dataforseo_client()
        status = dataforseo_client.get_status()
        
        if status.get('tasks') and status['tasks'][0].get('result'):
            result = status['tasks'][0]['result'][0]
            return jsonify({
                'success': True,
                'balance': {
                    'money': result.get('money', {}).get('balance', 0),
                    'currency': 'USD'
                },
                'rates': {
                    'keywords_for_keywords': result.get('rates', {}).get('keywords_data', {}).get('google_ads', {}).get('keywords_for_keywords', {}).get('live', 0.05),
                    'serp': result.get('rates', {}).get('serp', {}).get('live', {}).get('regular', 0.01)
                }
            })
    except ValueError as e:
        return jsonify({
            'success': False,
            'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
        }), 400
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@dataforseo_bp.route('/locations', methods=['GET'])
def get_locations():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ª–æ–∫–∞—Ü–∏–π"""
    try:
        country = request.args.get('country')
        dataforseo_client = get_dataforseo_client()
        locations = dataforseo_client.get_locations(country)
        
        popular = [
            {'code': 2804, 'name': 'Ukraine', 'name_ru': '–£–∫—Ä–∞–∏–Ω–∞'},
            {'code': 2840, 'name': 'United States', 'name_ru': '–°–®–ê'},
            {'code': 2643, 'name': 'Russia', 'name_ru': '–†–æ—Å—Å–∏—è'},
            {'code': 2276, 'name': 'Germany', 'name_ru': '–ì–µ—Ä–º–∞–Ω–∏—è'},
            {'code': 2826, 'name': 'United Kingdom', 'name_ru': '–í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è'},
            {'code': 2250, 'name': 'France', 'name_ru': '–§—Ä–∞–Ω—Ü–∏—è'},
            {'code': 2616, 'name': 'Poland', 'name_ru': '–ü–æ–ª—å—à–∞'},
            {'code': 2724, 'name': 'Spain', 'name_ru': '–ò—Å–ø–∞–Ω–∏—è'},
            {'code': 2380, 'name': 'Italy', 'name_ru': '–ò—Ç–∞–ª–∏—è'},
            {'code': 2124, 'name': 'Canada', 'name_ru': '–ö–∞–Ω–∞–¥–∞'},
        ]
        
        return jsonify({
            'success': True,
            'popular': popular,
            'all': locations.get('tasks', [{}])[0].get('result', []) if locations else []
        })
    except ValueError as e:
        return jsonify({'success': False, 'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'}), 400
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
        
@dataforseo_bp.route('/test-serp', methods=['POST'])
def test_serp_single():
    """–¢–µ—Å—Ç–æ–≤—ã–π SERP –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞"""
    try:
        data = request.json
        test_keyword = data.get('keyword', '—É—Ä–æ–∫–∏ –º—É–∑—ã–∫–∏ –∫–∏–µ–≤')
        
        log_print(f"üß™ –¢–ï–°–¢ SERP –¥–ª—è: {test_keyword}")
        
        # –ü–æ–ª—É—á–∞–µ–º DataForSeo –∫–ª–∏–µ–Ω—Ç
        try:
            dataforseo_client = get_dataforseo_client()
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
            }), 400
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞
        serp_response = dataforseo_client.get_serp(
            keyword=test_keyword,
            location_code=2804,  # Ukraine
            language_code='ru',
            device='desktop',
            os='windows',
            depth=10,  # –¢–æ–ª—å–∫–æ —Ç–æ–ø-10 –¥–ª—è —Ç–µ—Å—Ç–∞
            se_domain='google.com.ua'
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
        if not serp_response.get('tasks'):
            return jsonify({
                'success': False,
                'error': 'No response from DataForSeo'
            })
        
        task = serp_response['tasks'][0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
        if task.get('status_code') != 20000:
            return jsonify({
                'success': False,
                'error': task.get('status_message', 'Unknown error'),
                'status_code': task.get('status_code')
            })
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not task.get('result'):
            return jsonify({
                'success': False,
                'error': 'No results in response'
            })
        
        result = task['result'][0]
        items = result.get('items', [])
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –æ—Ç—á–µ—Ç
        report = {
            'keyword': test_keyword,
            'items_count': len(items),
            'cost': task.get('cost', 0),
            'types_found': [],
            'organic_domains': [],
            'has_ads': False,
            'has_maps': False
        }
        
        for item in items:
            item_type = item.get('type', '')
            
            if item_type not in report['types_found']:
                report['types_found'].append(item_type)
            
            if item_type == 'organic':
                domain = item.get('domain', '')
                if domain:
                    report['organic_domains'].append({
                        'position': item.get('rank_absolute', 0),
                        'domain': domain,
                        'title': item.get('title', '')[:50]
                    })
            elif item_type in ['paid', 'google_ads']:
                report['has_ads'] = True
            elif item_type in ['local_pack', 'maps']:
                report['has_maps'] = True
        
        log_print("‚úÖ –¢–ï–°–¢ SERP —É—Å–ø–µ—à–µ–Ω!")
        log_print(f"   –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {report['items_count']}")
        log_print(f"   –¢–∏–ø—ã: {', '.join(report['types_found'])}")
        log_print(f"   –°—Ç–æ–∏–º–æ—Å—Ç—å: ${report['cost']}")
        
        return jsonify({
            'success': True,
            'message': 'SERP API —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!',
            'report': report,
            'raw_response_preview': {
                'status_code': task.get('status_code'),
                'status_message': task.get('status_message'),
                'cost': task.get('cost'),
                'result_count': result.get('items_count', 0),
                'se_results_count': result.get('se_results_count', 0)
            }
        })
        
    except Exception as e:
        log_print(f"‚ùå Test SERP error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@dataforseo_bp.route('/languages', methods=['GET'])
def get_languages():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤"""
    try:
        dataforseo_client = get_dataforseo_client()
        languages = dataforseo_client.get_languages()
        
        main_languages = [
            {'code': 'ru', 'name': '–†—É—Å—Å–∫–∏–π'},
            {'code': 'uk', 'name': '–£–∫—Ä–∞–∏–Ω—Å–∫–∏–π'},
            {'code': 'en', 'name': '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π'},
            {'code': 'de', 'name': '–ù–µ–º–µ—Ü–∫–∏–π'},
            {'code': 'fr', 'name': '–§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π'},
            {'code': 'es', 'name': '–ò—Å–ø–∞–Ω—Å–∫–∏–π'},
            {'code': 'it', 'name': '–ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π'},
            {'code': 'pl', 'name': '–ü–æ–ª—å—Å–∫–∏–π'},
        ]
        
        return jsonify({
            'success': True,
            'main': main_languages,
            'all': languages.get('tasks', [{}])[0].get('result', []) if languages else []
        })
    except ValueError as e:
        return jsonify({'success': False, 'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'}), 400
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
        
def parse_serp_response(serp_response: Dict, campaign_id: int, connection, keyword_id: int = None, keyword_text: str = None) -> Dict:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ SERP –æ—Ç–≤–µ—Ç–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
    """
    try:
        if not serp_response.get('tasks'):
            log_print("‚ùå No tasks in SERP response")
            return None
        
        task = serp_response['tasks'][0]
        if task.get('status_code') != 20000:
            log_print(f"‚ùå SERP API error: {task.get('status_message')}")
            return None
        
        if not task.get('result') or len(task['result']) == 0:
            log_print("‚ùå No result in SERP response")
            return None
        
        result = task['result'][0]
        
        # –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–¥–∞—á–µ
        item_types = result.get('item_types', [])
        items_count = result.get('items_count', 0)
        se_results_count = result.get('se_results_count', 0)
        
        log_print(f"üìä SERP –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
        log_print(f"   - –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {items_count}")
        log_print(f"   - SE —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {se_results_count}")
        log_print(f"   - –¢–∏–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {', '.join(item_types) if item_types else 'none'}")
        
        items = result.get('items', [])
        
        if not items:
            log_print("‚ö†Ô∏è No items in SERP response")
            return None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        has_ads = False
        has_google_maps = False
        has_our_site = False
        has_school_sites = False
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏ –∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        organic_results = []
        paid_results = []
        maps_results = []
        all_items_parsed = []  # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ JSON
        
        # –°—á–µ—Ç—á–∏–∫–∏
        total_organic_sites = 0
        school_sites_count = 0
        school_domains_found = []
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–º–µ–Ω –Ω–∞—à–µ–≥–æ —Å–∞–π—Ç–∞
        our_domain = get_campaign_domain(campaign_id, connection)
        log_print(f"üìå –ù–∞—à –¥–æ–º–µ–Ω –¥–ª—è –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id}: {our_domain or '–ù–ï –£–ö–ê–ó–ê–ù'}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤ —à–∫–æ–ª
        school_domains = get_school_domains(connection)
        log_print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–º–µ–Ω–æ–≤ —à–∫–æ–ª-–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {len(school_domains)}")
        if school_domains:
            log_print(f"   –î–æ–º–µ–Ω—ã —à–∫–æ–ª: {', '.join(list(school_domains)[:5])}")
        
        # –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        log_print("\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –í–´–î–ê–ß–ò:")
        log_print("-" * 50)
        
        for idx, item in enumerate(items):
            item_type = item.get('type', '')
            position = item.get('rank_absolute', idx + 1)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            item_parsed = {
                'position': position,
                'type': item_type,
                'domain': item.get('domain', ''),
                'url': item.get('url', ''),
                'title': item.get('title', '')[:100] if item.get('title') else ''
            }
            
            # –†–ï–ö–õ–ê–ú–ù–´–ï –ë–õ–û–ö–ò
            if item_type in ['paid', 'google_ads', 'shopping', 'commercial_units']:
                has_ads = True
                paid_results.append(item_parsed)
                log_print(f"   #{position} [–†–ï–ö–õ–ê–ú–ê] {item.get('domain', 'unknown')}")
                log_print(f"        URL: {item.get('url', '')[:80]}")
            
            # GOOGLE MAPS
            elif item_type in ['local_pack', 'maps', 'map', 'google_maps']:
                has_google_maps = True
                maps_results.append(item_parsed)
                log_print(f"   #{position} [–ö–ê–†–¢–´] Google Maps –±–ª–æ–∫")
                if item.get('items'):
                    log_print(f"        –ú–µ—Å—Ç –≤ –±–ª–æ–∫–µ: {len(item.get('items', []))}")
            
            # –û–†–ì–ê–ù–ò–ß–ï–°–ö–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´
            elif item_type == 'organic':
                total_organic_sites += 1
                
                url = item.get('url', '').lower()
                domain = item.get('domain', '').lower()
                title = item.get('title', '')
                description = item.get('description', '')
                
                # –û—á–∏—â–∞–µ–º –¥–æ–º–µ–Ω
                clean_domain = domain.replace('www.', '') if domain else ''
                
                organic_results.append({
                    'position': position,
                    'domain': clean_domain,
                    'title': title[:100],
                    'url': url,
                    'description': description[:200]
                })
                
                log_print(f"   #{position} [–û–†–ì–ê–ù–ò–ö–ê] {clean_domain}")
                log_print(f"        Title: {title[:60]}")
                log_print(f"        URL: {url[:80]}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—à —Å–∞–π—Ç
                if our_domain:
                    if our_domain in url or our_domain == clean_domain:
                        has_our_site = True
                        log_print(f"        ‚úÖ –≠–¢–û –ù–ê–® –°–ê–ô–¢!")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∞–π—Ç–æ–≤ —à–∫–æ–ª
                if clean_domain in school_domains:
                    school_sites_count += 1
                    school_domains_found.append(clean_domain)
                    has_school_sites = True
                    log_print(f"        üè´ –≠–¢–û –°–ê–ô–¢ –®–ö–û–õ–´-–ö–û–ù–ö–£–†–ï–ù–¢–ê!")
            
            # –î–†–£–ì–ò–ï –¢–ò–ü–´
            else:
                log_print(f"   #{position} [{item_type.upper()}]")
                if item_type == 'people_also_ask':
                    log_print(f"        –í–æ–ø—Ä–æ—Å–æ–≤: {len(item.get('items', []))}")
                elif item_type == 'video':
                    log_print(f"        –í–∏–¥–µ–æ –±–ª–æ–∫")
                elif item_type == 'images':
                    log_print(f"        –ë–ª–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                elif item_type == 'related_searches':
                    log_print(f"        –ü–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã: {len(item.get('items', []))}")
            
            all_items_parsed.append(item_parsed)
        
        log_print("-" * 50)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Ç–∞
        intent_type = '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π'
        school_percentage = 0
        
        if has_school_sites and total_organic_sites > 0:
            school_percentage = (school_sites_count / total_organic_sites) * 100
            log_print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ–Ω—Ç–∞:")
            log_print(f"   –û—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∞–π—Ç–æ–≤: {total_organic_sites}")
            log_print(f"   –°–∞–π—Ç–æ–≤ —à–∫–æ–ª: {school_sites_count}")
            log_print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —à–∫–æ–ª: {school_percentage:.1f}%")
            
            if school_percentage >= 60:
                intent_type = '–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π'
                log_print(f"   ‚Üí –ò–Ω—Ç–µ–Ω—Ç: –ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ô (—à–∫–æ–ª >= 60%)")
            else:
                log_print(f"   ‚Üí –ò–Ω—Ç–µ–Ω—Ç: –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–´–ô (—à–∫–æ–ª < 60%)")
        
        # –°–û–•–†–ê–ù–Ø–ï–ú –í –ë–î –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if keyword_id and connection:
            try:
                cursor = connection.cursor()
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
                import json
                raw_response_json = json.dumps({
                    'status_code': task.get('status_code'),
                    'items_count': items_count,
                    'se_results_count': se_results_count,
                    'item_types': item_types
                }, ensure_ascii=False)
                
                parsed_items_json = json.dumps({
                    'organic': organic_results,
                    'paid': paid_results,
                    'maps': maps_results,
                    'all_items': all_items_parsed
                }, ensure_ascii=False)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É serp_logs
                cursor.execute("""
                    INSERT INTO serp_logs (
                        keyword_id, keyword_text, location_code, language_code,
                        device, depth, total_items, organic_count, paid_count,
                        maps_count, shopping_count, has_ads, has_maps,
                        has_our_site, has_school_sites, intent_type,
                        school_percentage, cost, raw_response, parsed_items
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                        %s, %s, %s, %s, %s, %s, %s
                    )
                """, (
                    keyword_id,
                    keyword_text or '',
                    task.get('data', [{}])[0].get('location_code', 0),
                    task.get('data', [{}])[0].get('language_code', ''),
                    task.get('data', [{}])[0].get('device', ''),
                    task.get('data', [{}])[0].get('depth', 0),
                    items_count,
                    total_organic_sites,
                    len(paid_results),
                    len(maps_results),
                    0,  # shopping_count
                    has_ads,
                    has_google_maps,
                    has_our_site,
                    has_school_sites,
                    intent_type,
                    school_percentage,
                    task.get('cost', 0),
                    raw_response_json,
                    parsed_items_json
                ))
                
                connection.commit()
                cursor.close()
                
                log_print(f"üíæ SERP –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î (serp_logs)")
                
            except Exception as e:
                log_print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ serp_logs: {str(e)}")
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
        log_print("\n" + "=" * 50)
        log_print(f"üìä –ò–¢–û–ì–ò SERP –ê–ù–ê–õ–ò–ó–ê:")
        log_print(f"   –û—Ä–≥–∞–Ω–∏–∫–∞: {total_organic_sites}")
        log_print(f"   –†–µ–∫–ª–∞–º–∞: {len(paid_results)}")
        log_print(f"   –ö–∞—Ä—Ç—ã: {len(maps_results)}")
        log_print(f"   –ù–∞—à —Å–∞–π—Ç: {'–î–ê' if has_our_site else '–ù–ï–¢'}")
        log_print(f"   –°–∞–π—Ç—ã —à–∫–æ–ª: {'–î–ê' if has_school_sites else '–ù–ï–¢'}")
        log_print(f"   –ò–Ω—Ç–µ–Ω—Ç: {intent_type}")
        log_print("=" * 50)
        
        return {
            'has_ads': has_ads,
            'has_school_sites': has_school_sites,
            'has_google_maps': has_google_maps,
            'has_our_site': has_our_site,
            'intent_type': intent_type,
            'stats': {
                'total_organic': total_organic_sites,
                'paid_count': len(paid_results),
                'maps_count': len(maps_results),
                'school_percentage': round(school_percentage, 1)
            }
        }
        
    except Exception as e:
        log_print(f"‚ùå Error parsing SERP response: {str(e)}")
        import traceback
        traceback.print_exc()
        return None
        
def get_campaign_domain(campaign_id: int, connection) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–æ–º–µ–Ω —Å–∞–π—Ç–∞ –¥–ª—è –∫–∞–º–ø–∞–Ω–∏–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã campaign_sites
    """
    try:
        cursor = connection.cursor()
        cursor.execute("""
            SELECT domain 
            FROM campaign_sites 
            WHERE campaign_id = %s
        """, (campaign_id,))
        
        result = cursor.fetchone()
        cursor.close()
        
        if result and result['domain']:
            domain = result['domain'].lower()
            # –£–±–∏—Ä–∞–µ–º www. –µ—Å–ª–∏ –µ—Å—Ç—å
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain
        
        return None
        
    except Exception as e:
        log_print(f"‚ùå Error getting campaign domain: {e}")
        return None


def get_school_domains(connection) -> set:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤ —à–∫–æ–ª-–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏–∑ –ë–î
    """
    try:
        cursor = connection.cursor()
        cursor.execute("""
            SELECT domain 
            FROM school_sites 
            WHERE is_active = TRUE
        """)
        
        results = cursor.fetchall()
        cursor.close()
        
        # –°–æ–∑–¥–∞–µ–º set –¥–æ–º–µ–Ω–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        domains = set()
        for row in results:
            if row['domain']:
                domain = row['domain'].lower()
                # –£–±–∏—Ä–∞–µ–º www. –µ—Å–ª–∏ –µ—Å—Ç—å
                if domain.startswith('www.'):
                    domain = domain[4:]
                domains.add(domain)
        
        return domains
        
    except Exception as e:
        log_print(f"‚ö†Ô∏è Error getting school domains: {e}")
        # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π set
        return set()