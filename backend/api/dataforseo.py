# api/dataforseo.py - –ü–û–õ–ù–û–°–¢–¨–Æ –ü–ï–†–ï–†–ê–ë–û–¢–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø
import sys
import json
from typing import Dict
from flask import Blueprint, request, jsonify, Response
from config import Config
import pymysql
from typing import Dict
from datetime import datetime
from services.dataforseo_client import get_dataforseo_client, DataForSeoClient
from api.keywords import get_random_batch_color

dataforseo_bp = Blueprint('dataforseo', __name__)

# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π flush –¥–ª—è –ª–æ–≥–æ–≤
def log_print(*args, **kwargs):
    print(*args, **kwargs)
    sys.stdout.flush()

def get_db_connection():
    """–°–æ–∑–¥–∞—ë—Ç –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
    return pymysql.connect(
        host=Config.DB_HOST,
        port=Config.DB_PORT,
        user=Config.DB_USER,
        password=Config.DB_PASSWORD,
        database=Config.DB_NAME,
        cursorclass=pymysql.cursors.DictCursor
    )

@dataforseo_bp.route('/test', methods=['GET', 'POST'])
def test_endpoint():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç endpoint"""
    try:
        log_print("üß™ TEST ENDPOINT –í–´–ó–í–ê–ù!")
        log_print(f"   Method: {request.method}")
        if request.method == 'POST':
            data = request.get_json()
            log_print(f"   Data: {data}")
        
        return jsonify({
            'success': True,
            'message': 'Test endpoint —Ä–∞–±–æ—Ç–∞–µ—Ç!',
            'method': request.method,
            'timestamp': str(datetime.utcnow())
        })
    except Exception as e:
        log_print(f"‚ùå Test endpoint error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@dataforseo_bp.route('/get-keywords-simple', methods=['POST'])
def get_keywords_simple():
    """–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ DataForSeo"""
    try:
        log_print("üß™ SIMPLE TEST –í–´–ó–í–ê–ù!")
        data = request.get_json()
        log_print(f"   –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {list(data.keys()) if data else 'None'}")
        
        # –ò–º–∏—Ç–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—É
        import time
        time.sleep(1)
        
        return jsonify({
            'success': True,
            'message': '–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!',
            'received_keys': list(data.keys()) if data else [],
            'stats': {
                'total_results': 5,
                'added': 3,
                'updated': 2,
                'errors': 0,
                'cost': 0.00
            }
        })
    except Exception as e:
        log_print(f"‚ùå Simple test error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@dataforseo_bp.route('/get-keywords', methods=['POST'])
def get_new_keywords():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –≤—ã–¥–∞—á–∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —á–µ—Ä–µ–∑ DataForSeo"""
    connection = None
    
    log_print("=" * 50)
    log_print("üöÄ GET-KEYWORDS ENDPOINT –í–´–ó–í–ê–ù!")
    log_print("=" * 50)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'No data in request'}), 400
        
        seed_keywords = data.get('seed_keywords', [])
        ad_group_id = data.get('ad_group_id')
        
        log_print(f"üîë Seed keywords count: {len(seed_keywords)}")
        log_print(f"üè∑Ô∏è  Ad group ID: {ad_group_id}")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã API —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        location_code = data.get('location_code', 2804)
        language_code = data.get('language_code', 'ru')
        limit = data.get('limit', 700)
        search_partners = data.get('search_partners', False)
        include_seed_keyword = data.get('include_seed_keyword', True)
        sort_by = data.get('sort_by', 'relevance')
        date_from = data.get('date_from', '2024-01-01')
        date_to = data.get('date_to')
        
        if not seed_keywords:
            return jsonify({'success': False, 'error': 'No seed keywords provided'}), 400
        
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –ë–î
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –≥—Ä—É–ø–ø—É –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        cursor.execute("SELECT * FROM ad_groups WHERE id = %s", (ad_group_id,))
        ad_group = cursor.fetchone()
        
        if not ad_group:
            return jsonify({'success': False, 'error': 'Ad group not found'}), 404
        
        campaign_id = ad_group['campaign_id']
        
        # –ó–∞–ø—Ä–æ—Å –∫ DataForSeo
        try:
            dataforseo_client = get_dataforseo_client()
            
            response = dataforseo_client.get_keywords_for_keywords(
                keywords=seed_keywords,
                location_code=location_code,
                language_code=language_code,
                search_partners=search_partners,
                sort_by=sort_by,
                limit=limit,
                include_seed_keyword=include_seed_keyword,
                date_from=date_from,
                date_to=date_to
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
            if not response.get('tasks'):
                return jsonify({
                    'success': False,
                    'error': 'No data received from DataForSeo'
                }), 500
            
            task = response['tasks'][0]
            if task.get('status_code') != 20000:
                error_msg = task.get('status_message', 'Unknown error')
                return jsonify({
                    'success': False,
                    'error': f"DataForSeo error: {error_msg}"
                }), 500
            
            request_cost = task.get('cost', 0.05)
            log_print(f"üí∞ –°—Ç–æ–∏–º–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞: ${request_cost}")
            
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
            }), 400
        except Exception as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API error: {str(e)}'
            }), 500
        
        # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
        try:
            keywords_data = dataforseo_client.parse_keywords_response(response)
            log_print(f"üìà –ü–æ–ª—É—á–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(keywords_data)}")
        except Exception as e:
            log_print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {str(e)}")
            keywords_data = []
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ü–≤–µ—Ç –¥–ª—è –Ω–æ–≤–æ–π –ø–∞—Ä—Ç–∏–∏
        batch_color = get_random_batch_color()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –ë–î
        added_count = 0
        updated_count = 0
        errors = []
        
        for kw_data in keywords_data:
            try:
                keyword_text = kw_data['keyword']
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ
                cursor.execute(
                    "SELECT * FROM keywords WHERE ad_group_id = %s AND keyword = %s",
                    (ad_group_id, keyword_text)
                )
                existing = cursor.fetchone()
                
                if existing:
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ (—Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
                    update_query = """
                        UPDATE keywords SET 
                            avg_monthly_searches = %s,
                            competition = %s,
                            competition_percent = %s,
                            min_top_of_page_bid = %s,
                            max_top_of_page_bid = %s,
                            three_month_change = %s,
                            yearly_change = %s,
                            max_cpc = %s,
                            updated_at = NOW()
                        WHERE id = %s
                    """
                    
                    update_data = (
                        kw_data.get('avg_monthly_searches', 0),
                        kw_data.get('competition', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                        kw_data.get('competition_percent', 0),
                        kw_data.get('min_top_of_page_bid', 0),
                        kw_data.get('max_top_of_page_bid', 0),
                        kw_data.get('three_month_change'),
                        kw_data.get('yearly_change'),
                        kw_data.get('cpc', existing['max_cpc']),
                        existing['id']
                    )
                    
                    cursor.execute(update_query, update_data)
                    updated_count += 1
                else:
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ
                    insert_query = """
                        INSERT INTO keywords (
                            campaign_id, ad_group_id, keyword, criterion_type, status,
                            avg_monthly_searches, competition, competition_percent,
                            min_top_of_page_bid, max_top_of_page_bid, three_month_change,
                            yearly_change, max_cpc, intent_type, is_new, batch_color,
                            has_ads, has_school_sites, has_google_maps, has_our_site
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    """
                    
                    insert_data = (
                        campaign_id,
                        ad_group_id,
                        keyword_text,
                        'Phrase',
                        'Enabled',
                        kw_data.get('avg_monthly_searches', 0),
                        kw_data.get('competition', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                        kw_data.get('competition_percent', 0),
                        kw_data.get('min_top_of_page_bid', 0),
                        kw_data.get('max_top_of_page_bid', 0),
                        kw_data.get('three_month_change'),
                        kw_data.get('yearly_change'),
                        kw_data.get('cpc', 3.61),
                        '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π',  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ —á–µ—Ä–µ–∑ SERP
                        True,  # is_new
                        batch_color,  # batch_color
                        False,  # has_ads - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        False,  # has_school_sites - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        False,  # has_google_maps - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                        False   # has_our_site - –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                    )
                    
                    cursor.execute(insert_query, insert_data)
                    added_count += 1
                    
            except Exception as e:
                errors.append(f"Error processing '{kw_data.get('keyword', 'unknown')}': {str(e)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        connection.commit()
        
        result = {
            'success': True,
            'message': f'–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(keywords_data)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤. –î–æ–±–∞–≤–ª–µ–Ω–æ: {added_count}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ: {updated_count}',
            'stats': {
                'total_results': len(keywords_data),
                'added': added_count,
                'updated': updated_count,
                'errors': len(errors),
                'cost': request_cost
            },
            'cost': request_cost
        }
        
        if errors:
            result['errors'] = errors[:10]
        
        return jsonify(result)
        
    except Exception as e:
        if connection:
            connection.rollback()
        log_print(f"üí• –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()

@dataforseo_bp.route('/apply-serp', methods=['POST'])
def apply_serp_analysis():
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ SERP –∞–Ω–∞–ª–∏–∑–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤"""
    connection = None
    
    try:
        data = request.json
        keyword_ids = data.get('keyword_ids', [])
        
        if not keyword_ids:
            return jsonify({'success': False, 'error': 'No keywords selected'}), 400
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        placeholders = ','.join(['%s'] * len(keyword_ids))
        cursor.execute(f"""
            SELECT k.id, k.keyword, k.campaign_id 
            FROM keywords k
            WHERE k.id IN ({placeholders})
        """, keyword_ids)
        keywords_data = cursor.fetchall()
        
        # –ü–æ–ª—É—á–∞–µ–º DataForSeo –∫–ª–∏–µ–Ω—Ç
        try:
            dataforseo_client = get_dataforseo_client()
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
            }), 400
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã SERP –∑–∞–ø—Ä–æ—Å–∞
        serp_params = {
            'location_code': data.get('location_code', 2804),
            'language_code': data.get('language_code', 'ru'),
            'device': data.get('device', 'desktop'),
            'os': data.get('os', 'windows'),
            'depth': data.get('depth', 100),
            'se_domain': data.get('se_domain', 'google.com.ua')
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—é: live –¥–ª—è <10, batch –¥–ª—è >=10
        if len(keywords_data) < 10:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π live –ø–æ–¥—Ö–æ–¥
            return _process_serp_live(keywords_data, serp_params, connection, dataforseo_client)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º batch –ø–æ–¥—Ö–æ–¥ —á–µ—Ä–µ–∑ task_post
            return _process_serp_batch(keywords_data, serp_params, connection, dataforseo_client)
            
    except Exception as e:
        if connection:
            connection.rollback()
        log_print(f"‚ùå Error in apply_serp_analysis: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()

def _process_serp_batch(keywords_data, serp_params, connection, dataforseo_client):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ SERP —á–µ—Ä–µ–∑ task_post –¥–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤"""
    
    log_print(f"üöÄ Batch SERP –¥–ª—è {len(keywords_data)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤")
    
    # –®–∞–≥ 1: –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ —á–µ—Ä–µ–∑ task_post
    task_ids = []
    batch_size = 100  # –ú–∞–∫—Å–∏–º—É–º –∑–∞–¥–∞—á –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ
    
    for i in range(0, len(keywords_data), batch_size):
        batch = keywords_data[i:i+batch_size]
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è batch –∑–∞–ø—Ä–æ—Å–∞
        tasks = []
        for kw in batch:
            task_data = {
                "keyword": kw['keyword'],
                "tag": f"keyword_id_{kw['id']}",  # –¢–µ–≥ –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
                **serp_params
            }
            tasks.append(task_data)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º batch –∑–∞–ø—Ä–æ—Å
        response = dataforseo_client.post_serp_tasks(tasks)
        
        if response.get('tasks'):
            for task in response['tasks']:
                if task.get('id'):
                    task_ids.append({
                        'task_id': task['id'],
                        'keyword_id': int(task.get('data', {}).get('tag', '').replace('keyword_id_', '')),
                        'keyword': next((kw['keyword'] for kw in batch if str(kw['id']) in task.get('data', {}).get('tag', '')), '')
                    })
        
        log_print(f"üìã –°–æ–∑–¥–∞–Ω–æ {len(task_ids)} –∑–∞–¥–∞—á")
    
    # –®–∞–≥ 2: –ñ–¥–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á
    import time
    max_wait = 120  # –ú–∞–∫—Å–∏–º—É–º 2 –º–∏–Ω—É—Ç—ã –æ–∂–∏–¥–∞–Ω–∏—è
    start_time = time.time()
    completed_tasks = []
    
    while len(completed_tasks) < len(task_ids) and time.time() - start_time < max_wait:
        time.sleep(2)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á
        ready_tasks = dataforseo_client.get_tasks_ready()
        
        for task_info in task_ids:
            if task_info['task_id'] not in [t['task_id'] for t in completed_tasks]:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏
                if task_info['task_id'] in ready_tasks:
                    completed_tasks.append(task_info)
                    log_print(f"‚úÖ –ó–∞–¥–∞—á–∞ –≥–æ—Ç–æ–≤–∞: {task_info['keyword'][:30]}...")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞ frontend —á–µ—Ä–µ–∑ SSE –∏–ª–∏ WebSocket
        progress_percent = (len(completed_tasks) / len(task_ids)) * 100
        log_print(f"‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: {len(completed_tasks)}/{len(task_ids)} ({progress_percent:.0f}%)")
    
    # –®–∞–≥ 3: –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    updated_count = 0
    errors = []
    total_cost = 0
    
    for task_info in completed_tasks:
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–¥–∞—á–∏
            result = dataforseo_client.get_task_result(task_info['task_id'])
            
            # –ü–∞—Ä—Å–∏–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –ë–î
            serp_data = parse_serp_response(
                result,
                keywords_data[0]['campaign_id'],
                connection,
                keyword_id=task_info['keyword_id'],
                keyword_text=task_info['keyword']
            )
            
            if serp_data:
                cursor = connection.cursor()
                cursor.execute("""
                    UPDATE keywords 
                    SET 
                        has_ads = %s,
                        has_school_sites = %s,
                        has_google_maps = %s,
                        has_our_site = %s,
                        intent_type = %s,
                        last_serp_check = NOW(),
                        updated_at = NOW()
                    WHERE id = %s
                """, (
                    serp_data['has_ads'],
                    serp_data['has_school_sites'],
                    serp_data['has_google_maps'],
                    serp_data['has_our_site'],
                    serp_data['intent_type'],
                    task_info['keyword_id']
                ))
                cursor.close()
                updated_count += 1
                
                # –°—á–∏—Ç–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
                if result.get('cost'):
                    total_cost += result['cost']
                    
        except Exception as e:
            errors.append(f"–û—à–∏–±–∫–∞ –¥–ª—è '{task_info['keyword']}': {str(e)}")
    
    connection.commit()
    
    return jsonify({
        'success': True,
        'message': f'Batch SERP –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {updated_count} –∏–∑ {len(keywords_data)} —Å–ª–æ–≤',
        'updated': updated_count,
        'total': len(keywords_data),
        'errors': errors[:10] if errors else [],
        'cost': round(total_cost, 4),
        'method': 'batch_task_post'
    })

def _process_serp_live(keywords_data, serp_params, connection, dataforseo_client):
    connection = None
    
    try:
        data = request.json
        keyword_ids = data.get('keyword_ids', [])
        
        if not keyword_ids:
            return jsonify({'success': False, 'error': 'No keywords selected'}), 400
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Å campaign_id
        placeholders = ','.join(['%s'] * len(keyword_ids))
        cursor.execute(f"""
            SELECT k.id, k.keyword, k.campaign_id 
            FROM keywords k
            WHERE k.id IN ({placeholders})
        """, keyword_ids)
        keywords_data = cursor.fetchall()
        
        if not keywords_data:
            return jsonify({'success': False, 'error': 'Keywords not found'}), 404
        
        # –ü–æ–ª—É—á–∞–µ–º DataForSeo –∫–ª–∏–µ–Ω—Ç
        try:
            dataforseo_client = get_dataforseo_client()
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
            }), 400
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã SERP –∑–∞–ø—Ä–æ—Å–∞
        serp_params = {
            'location_code': data.get('location_code', 2804),
            'language_code': data.get('language_code', 'ru'),
            'device': data.get('device', 'desktop'),
            'os': data.get('os', 'windows'),
            'depth': data.get('depth', 100),
            'calculate_rectangles': data.get('calculate_rectangles', False),
            'browser_screen_width': data.get('browser_screen_width', 1920),
            'browser_screen_height': data.get('browser_screen_height', 1080),
            'se_domain': data.get('se_domain', 'google.com.ua')
        }
        
        updated_count = 0
        errors = []
        total_cost = 0
        results_summary = {
            'with_ads': 0,
            'with_maps': 0,
            'with_our_site': 0,
            'with_school_sites': 0,
            'commercial_intent': 0
        }
        
        for idx, kw in enumerate(keywords_data):
            try:
                log_print(f"\nüîç –ê–Ω–∞–ª–∏–∑ [{idx+1}/{len(keywords_data)}]: {kw['keyword']}")
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º SERP –∑–∞–ø—Ä–æ—Å
                serp_response = dataforseo_client.get_serp(
                    keyword=kw['keyword'],
                    **serp_params
                )
                
                # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                serp_data = parse_serp_response(
                    serp_response, 
                    kw['campaign_id'], 
                    connection,
                    keyword_id=kw['id'],
                    keyword_text=kw['keyword']
                )
                
                if serp_data:
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –Ω–∞—à–µ–≥–æ —Å–∞–π—Ç–∞
                    our_position = 0
                    if serp_response.get('tasks') and serp_response['tasks'][0].get('result'):
                        items = serp_response['tasks'][0]['result'][0].get('items', [])
                        for item in items:
                            if item.get('type') == 'organic':
                                domain = item.get('domain', '').lower().replace('www.', '')
                                # TODO: –ø–æ–ª—É—á–∞—Ç—å –¥–æ–º–µ–Ω –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∏–∑ campaign_sites
                                if domain == 'montessori.ua':
                                    our_position = item.get('rank_absolute', 0)
                                    break
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î —Å –ø–æ–∑–∏—Ü–∏–µ–π –∏ –¥–∞—Ç–æ–π
                    cursor.execute("""
                        UPDATE keywords 
                        SET 
                            has_ads = %s,
                            has_school_sites = %s,
                            has_google_maps = %s,
                            has_our_site = %s,
                            intent_type = %s,
                            last_serp_check = NOW(),
                            serp_position = %s,
                            updated_at = NOW()
                        WHERE id = %s
                    """, (
                        serp_data['has_ads'],
                        serp_data['has_school_sites'],
                        serp_data['has_google_maps'],
                        serp_data['has_our_site'],
                        serp_data['intent_type'],
                        our_position if our_position > 0 else None,
                        kw['id']
                    ))
                    
                    updated_count += 1
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    if serp_data['has_ads']:
                        results_summary['with_ads'] += 1
                    if serp_data['has_google_maps']:
                        results_summary['with_maps'] += 1
                    if serp_data['has_our_site']:
                        results_summary['with_our_site'] += 1
                    if serp_data['has_school_sites']:
                        results_summary['with_school_sites'] += 1
                    if serp_data['intent_type'] == '–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π':
                        results_summary['commercial_intent'] += 1
                    
                    # –°—á–∏—Ç–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
                    if serp_response.get('tasks'):
                        task_cost = serp_response['tasks'][0].get('cost', 0.003)
                        total_cost += task_cost
                    
                    log_print(f"   ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ")
                else:
                    error_msg = f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è '{kw['keyword']}'"
                    errors.append(error_msg)
                    log_print(f"   ‚ö†Ô∏è {error_msg}")
                    
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –¥–ª—è '{kw['keyword']}': {str(e)}"
                errors.append(error_msg)
                log_print(f"   ‚ùå {error_msg}")
                import traceback
                traceback.print_exc()
        
        connection.commit()
        cursor.close()
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        message = f'SERP –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {updated_count} –∏–∑ {len(keywords_data)} —Å–ª–æ–≤'
        
        log_print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã SERP –∞–Ω–∞–ª–∏–∑–∞:")
        log_print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {updated_count}/{len(keywords_data)}")
        log_print(f"   –û—à–∏–±–æ–∫: {len(errors)}")
        log_print(f"   –°—Ç–æ–∏–º–æ—Å—Ç—å: ${total_cost:.4f}")
        
        return jsonify({
            'success': True,
            'message': message,
            'updated': updated_count,
            'total': len(keywords_data),
            'errors': errors[:10] if errors else [],
            'cost': round(total_cost, 4),
            'summary': results_summary
        })
        
    except Exception as e:
        if connection:
            connection.rollback()
        log_print(f"‚ùå Error in apply_serp_analysis: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500
        
    finally:
        if connection:
            connection.close()
            
@dataforseo_bp.route('/serp-logs', methods=['GET'])
def get_serp_logs():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö SERP –∞–Ω–∞–ª–∏–∑–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    connection = None
    try:
        limit = request.args.get('limit', 20, type=int)
        keyword_id = request.args.get('keyword_id', None, type=int)
        
        connection = get_db_connection()
        cursor = connection.cursor()
        
        if keyword_id:
            # –õ–æ–≥–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            cursor.execute("""
                SELECT * FROM serp_logs 
                WHERE keyword_id = %s 
                ORDER BY created_at DESC 
                LIMIT %s
            """, (keyword_id, limit))
        else:
            # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –ª–æ–≥–∏
            cursor.execute("""
                SELECT * FROM serp_logs 
                ORDER BY created_at DESC 
                LIMIT %s
            """, (limit,))
        
        logs = cursor.fetchall()
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
        formatted_logs = []
        for log in logs:
            try:
                # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON
                raw_response = {}
                parsed_items = {}
                
                if log.get('raw_response'):
                    try:
                        raw_response = json.loads(log['raw_response'])
                    except:
                        raw_response = {}
                
                if log.get('parsed_items'):
                    try:
                        parsed_items = json.loads(log['parsed_items'])
                    except:
                        parsed_items = {}
                
                formatted_log = {
                    'id': log['id'],
                    'keyword': log.get('keyword_text', ''),
                    'created_at': log['created_at'].isoformat() if log.get('created_at') else None,
                    'summary': {
                        'total_items': log.get('total_items', 0),
                        'organic': log.get('organic_count', 0),
                        'paid': log.get('paid_count', 0),
                        'maps': log.get('maps_count', 0)
                    },
                    'flags': {
                        'has_ads': bool(log.get('has_ads')),
                        'has_maps': bool(log.get('has_maps')),
                        'has_our_site': bool(log.get('has_our_site')),
                        'has_school_sites': bool(log.get('has_school_sites'))
                    },
                    'intent': log.get('intent_type', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π'),
                    'school_percentage': float(log.get('school_percentage', 0)),
                    'cost': float(log.get('cost', 0)),
                    'raw_response': raw_response,
                    'parsed_items': parsed_items
                }
                formatted_logs.append(formatted_log)
            except Exception as e:
                log_print(f"‚ö†Ô∏è Error formatting log {log.get('id')}: {str(e)}")
                continue
        
        cursor.close()
        
        log_print(f"üìä Returning {len(formatted_logs)} SERP logs")
        
        return jsonify({
            'success': True,
            'count': len(formatted_logs),
            'logs': formatted_logs
        })
        
    except Exception as e:
        log_print(f"‚ùå Error getting SERP logs: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()


@dataforseo_bp.route('/serp-logs/<int:log_id>', methods=['GET'])
def get_serp_log_details(log_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º SERP –∞–Ω–∞–ª–∏–∑–µ"""
    connection = None
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        
        cursor.execute("SELECT * FROM serp_logs WHERE id = %s", (log_id,))
        log = cursor.fetchone()
        
        if not log:
            return jsonify({'success': False, 'error': 'Log not found'}), 404
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π —Ä–∞–∑–±–æ—Ä
        parsed_items = {}
        if log.get('parsed_items'):
            try:
                parsed_items = json.loads(log['parsed_items'])
            except:
                parsed_items = {}
        
        detailed_report = {
            'id': log['id'],
            'keyword': log.get('keyword_text', ''),
            'created_at': log['created_at'].isoformat() if log.get('created_at') else None,
            'parameters': {
                'location_code': log.get('location_code', 0),
                'language_code': log.get('language_code', ''),
                'device': log.get('device', ''),
                'depth': log.get('depth', 0)
            },
            'summary': {
                'total_items': log.get('total_items', 0),
                'organic_count': log.get('organic_count', 0),
                'paid_count': log.get('paid_count', 0),
                'maps_count': log.get('maps_count', 0)
            },
            'analysis_result': {
                'has_ads': bool(log.get('has_ads')),
                'has_maps': bool(log.get('has_maps')),
                'has_our_site': bool(log.get('has_our_site')),
                'has_school_sites': bool(log.get('has_school_sites')),
                'intent_type': log.get('intent_type', '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π'),
                'school_percentage': float(log.get('school_percentage', 0))
            },
            'cost': float(log.get('cost', 0)),
            'organic_results': parsed_items.get('organic', []),
            'paid_results': parsed_items.get('paid', []),
            'all_items': parsed_items.get('all_items', [])
        }
        
        cursor.close()
        
        return jsonify({
            'success': True,
            'report': detailed_report
        })
        
    except Exception as e:
        log_print(f"‚ùå Error getting SERP log details: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if connection:
            connection.close()

@dataforseo_bp.route('/test-connection', methods=['POST'])
def test_dataforseo_connection():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ DataForSeo API"""
    try:
        data = request.json
        temp_client = DataForSeoClient(data['login'], data['password'])
        status = temp_client.get_status()
        
        if status.get('tasks') and status['tasks'][0].get('result'):
            balance = status['tasks'][0]['result'][0].get('money', {}).get('balance', 0)
            return jsonify({
                'success': True, 
                'message': f'API —Ä–∞–±–æ—Ç–∞–µ—Ç. –ë–∞–ª–∞–Ω—Å: ${balance}'
            })
        else:
            return jsonify({'success': False, 'message': '–ù–µ–≤–µ—Ä–Ω—ã–µ —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ'})
    except Exception as e:
        return jsonify({'success': False, 'message': f'–û—à–∏–±–∫–∞ API: {str(e)}'})
        
@dataforseo_bp.route('/check-serp-cost', methods=['POST'])
def check_serp_cost():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ SERP –∞–Ω–∞–ª–∏–∑–∞ –ø–µ—Ä–µ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º"""
    try:
        data = request.json
        keyword_ids = data.get('keyword_ids', [])
        depth = data.get('depth', 100)
        
        # –†–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏
        base_cost = 0.003  # $0.003 –∑–∞ SERP regular –¥–æ 100 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
        # –ú–Ω–æ–∂–∏—Ç–µ–ª—å –¥–ª—è –≥–ª—É–±–∏–Ω—ã
        if depth <= 20:
            depth_multiplier = 1
        elif depth <= 50:
            depth_multiplier = 1.5
        elif depth <= 100:
            depth_multiplier = 2
        else:
            depth_multiplier = 3  # –¥–ª—è depth > 100
        
        estimated_cost = len(keyword_ids) * base_cost * depth_multiplier
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞
        try:
            dataforseo_client = get_dataforseo_client()
            status = dataforseo_client.get_status()
            
            current_balance = 0
            if status.get('tasks') and status['tasks'][0].get('result'):
                current_balance = status['tasks'][0]['result'][0].get('money', {}).get('balance', 0)
            
            can_proceed = current_balance >= estimated_cost
            
            return jsonify({
                'success': True,
                'estimated_cost': round(estimated_cost, 4),
                'current_balance': round(current_balance, 2),
                'can_proceed': can_proceed,
                'keywords_count': len(keyword_ids),
                'depth': depth,
                'message': f"–ê–Ω–∞–ª–∏–∑ {len(keyword_ids)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ ${estimated_cost:.4f}"
            })
            
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–ª–∞–Ω—Å, –≤—Å–µ —Ä–∞–≤–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–æ–∏–º–æ—Å—Ç—å
            return jsonify({
                'success': True,
                'estimated_cost': round(estimated_cost, 4),
                'current_balance': None,
                'can_proceed': True,
                'keywords_count': len(keyword_ids),
                'depth': depth,
                'message': f"–ê–Ω–∞–ª–∏–∑ {len(keyword_ids)} –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –±—É–¥–µ—Ç —Å—Ç–æ–∏—Ç—å –ø—Ä–∏–º–µ—Ä–Ω–æ ${estimated_cost:.4f}",
                'warning': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–ª–∞–Ω—Å'
            })
            
    except Exception as e:
        log_print(f"‚ùå Error checking SERP cost: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@dataforseo_bp.route('/check-balance', methods=['GET'])
def check_balance():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∏ —Å—Ç–∞—Ç—É—Å–∞ –∞–∫–∫–∞—É–Ω—Ç–∞ DataForSeo"""
    try:
        dataforseo_client = get_dataforseo_client()
        status = dataforseo_client.get_status()
        
        if status.get('tasks') and status['tasks'][0].get('result'):
            result = status['tasks'][0]['result'][0]
            return jsonify({
                'success': True,
                'balance': {
                    'money': result.get('money', {}).get('balance', 0),
                    'currency': 'USD'
                },
                'rates': {
                    'keywords_for_keywords': result.get('rates', {}).get('keywords_data', {}).get('google_ads', {}).get('keywords_for_keywords', {}).get('live', 0.05),
                    'serp': result.get('rates', {}).get('serp', {}).get('live', {}).get('regular', 0.01)
                }
            })
    except ValueError as e:
        return jsonify({
            'success': False,
            'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
        }), 400
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@dataforseo_bp.route('/locations', methods=['GET'])
def get_locations():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ª–æ–∫–∞—Ü–∏–π"""
    try:
        country = request.args.get('country')
        dataforseo_client = get_dataforseo_client()
        locations = dataforseo_client.get_locations(country)
        
        popular = [
            {'code': 2804, 'name': 'Ukraine', 'name_ru': '–£–∫—Ä–∞–∏–Ω–∞'},
            {'code': 2840, 'name': 'United States', 'name_ru': '–°–®–ê'},
            {'code': 2643, 'name': 'Russia', 'name_ru': '–†–æ—Å—Å–∏—è'},
            {'code': 2276, 'name': 'Germany', 'name_ru': '–ì–µ—Ä–º–∞–Ω–∏—è'},
            {'code': 2826, 'name': 'United Kingdom', 'name_ru': '–í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è'},
            {'code': 2250, 'name': 'France', 'name_ru': '–§—Ä–∞–Ω—Ü–∏—è'},
            {'code': 2616, 'name': 'Poland', 'name_ru': '–ü–æ–ª—å—à–∞'},
            {'code': 2724, 'name': 'Spain', 'name_ru': '–ò—Å–ø–∞–Ω–∏—è'},
            {'code': 2380, 'name': 'Italy', 'name_ru': '–ò—Ç–∞–ª–∏—è'},
            {'code': 2124, 'name': 'Canada', 'name_ru': '–ö–∞–Ω–∞–¥–∞'},
        ]
        
        return jsonify({
            'success': True,
            'popular': popular,
            'all': locations.get('tasks', [{}])[0].get('result', []) if locations else []
        })
    except ValueError as e:
        return jsonify({'success': False, 'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'}), 400
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
        
@dataforseo_bp.route('/test-serp', methods=['POST'])
def test_serp_single():
    """–¢–µ—Å—Ç–æ–≤—ã–π SERP –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞"""
    try:
        data = request.json
        test_keyword = data.get('keyword', '—É—Ä–æ–∫–∏ –º—É–∑—ã–∫–∏ –∫–∏–µ–≤')
        
        log_print(f"üß™ –¢–ï–°–¢ SERP –¥–ª—è: {test_keyword}")
        
        # –ü–æ–ª—É—á–∞–µ–º DataForSeo –∫–ª–∏–µ–Ω—Ç
        try:
            dataforseo_client = get_dataforseo_client()
        except ValueError as e:
            return jsonify({
                'success': False,
                'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'
            }), 400
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞
        serp_response = dataforseo_client.get_serp(
            keyword=test_keyword,
            location_code=2804,  # Ukraine
            language_code='ru',
            device='desktop',
            os='windows',
            depth=10,  # –¢–æ–ª—å–∫–æ —Ç–æ–ø-10 –¥–ª—è —Ç–µ—Å—Ç–∞
            se_domain='google.com.ua'
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
        if not serp_response.get('tasks'):
            return jsonify({
                'success': False,
                'error': 'No response from DataForSeo'
            })
        
        task = serp_response['tasks'][0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
        if task.get('status_code') != 20000:
            return jsonify({
                'success': False,
                'error': task.get('status_message', 'Unknown error'),
                'status_code': task.get('status_code')
            })
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if not task.get('result'):
            return jsonify({
                'success': False,
                'error': 'No results in response'
            })
        
        result = task['result'][0]
        items = result.get('items', [])
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –æ—Ç—á–µ—Ç
        report = {
            'keyword': test_keyword,
            'items_count': len(items),
            'cost': task.get('cost', 0),
            'types_found': [],
            'organic_domains': [],
            'has_ads': False,
            'has_maps': False
        }
        
        for item in items:
            item_type = item.get('type', '')
            
            if item_type not in report['types_found']:
                report['types_found'].append(item_type)
            
            if item_type == 'organic':
                domain = item.get('domain', '')
                if domain:
                    report['organic_domains'].append({
                        'position': item.get('rank_absolute', 0),
                        'domain': domain,
                        'title': item.get('title', '')[:50]
                    })
            elif item_type in ['paid', 'google_ads']:
                report['has_ads'] = True
            elif item_type in ['local_pack', 'maps']:
                report['has_maps'] = True
        
        log_print("‚úÖ –¢–ï–°–¢ SERP —É—Å–ø–µ—à–µ–Ω!")
        log_print(f"   –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {report['items_count']}")
        log_print(f"   –¢–∏–ø—ã: {', '.join(report['types_found'])}")
        log_print(f"   –°—Ç–æ–∏–º–æ—Å—Ç—å: ${report['cost']}")
        
        return jsonify({
            'success': True,
            'message': 'SERP API —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!',
            'report': report,
            'raw_response_preview': {
                'status_code': task.get('status_code'),
                'status_message': task.get('status_message'),
                'cost': task.get('cost'),
                'result_count': result.get('items_count', 0),
                'se_results_count': result.get('se_results_count', 0)
            }
        })
        
    except Exception as e:
        log_print(f"‚ùå Test SERP error: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@dataforseo_bp.route('/languages', methods=['GET'])
def get_languages():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —è–∑—ã–∫–æ–≤"""
    try:
        dataforseo_client = get_dataforseo_client()
        languages = dataforseo_client.get_languages()
        
        main_languages = [
            {'code': 'ru', 'name': '–†—É—Å—Å–∫–∏–π'},
            {'code': 'uk', 'name': '–£–∫—Ä–∞–∏–Ω—Å–∫–∏–π'},
            {'code': 'en', 'name': '–ê–Ω–≥–ª–∏–π—Å–∫–∏–π'},
            {'code': 'de', 'name': '–ù–µ–º–µ—Ü–∫–∏–π'},
            {'code': 'fr', 'name': '–§—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π'},
            {'code': 'es', 'name': '–ò—Å–ø–∞–Ω—Å–∫–∏–π'},
            {'code': 'it', 'name': '–ò—Ç–∞–ª—å—è–Ω—Å–∫–∏–π'},
            {'code': 'pl', 'name': '–ü–æ–ª—å—Å–∫–∏–π'},
        ]
        
        return jsonify({
            'success': True,
            'main': main_languages,
            'all': languages.get('tasks', [{}])[0].get('result', []) if languages else []
        })
    except ValueError as e:
        return jsonify({'success': False, 'error': f'DataForSeo API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω: {str(e)}'}), 400
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500
        
def parse_serp_response(serp_response: Dict, campaign_id: int, connection, keyword_id: int = None, keyword_text: str = None) -> Dict:
    """
    –ü–∞—Ä—Å–∏–Ω–≥ SERP –æ—Ç–≤–µ—Ç–∞ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
    """
    try:
        if not serp_response.get('tasks'):
            log_print("‚ùå No tasks in SERP response")
            return None
        
        task = serp_response['tasks'][0]
        if task.get('status_code') != 20000:
            log_print(f"‚ùå SERP API error: {task.get('status_message')}")
            return None
        
        if not task.get('result') or len(task['result']) == 0:
            log_print("‚ùå No result in SERP response")
            return None
        
        result = task['result'][0]
        
        # –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—ã–¥–∞—á–µ
        item_types = result.get('item_types', [])
        items_count = result.get('items_count', 0)
        se_results_count = result.get('se_results_count', 0)
        
        log_print(f"üìä SERP –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ:")
        log_print(f"   - –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {items_count}")
        log_print(f"   - SE —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {se_results_count}")
        log_print(f"   - –¢–∏–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {', '.join(item_types) if item_types else 'none'}")
        
        items = result.get('items', [])
        
        if not items:
            log_print("‚ö†Ô∏è No items in SERP response")
            return None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        has_ads = False
        has_google_maps = False
        has_our_site = False
        has_school_sites = False
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Å—á–µ—Ç—á–∏–∫–∏ –∏ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        organic_results = []
        paid_results = []
        maps_results = []
        all_items_parsed = []
        
        # –°—á–µ—Ç—á–∏–∫–∏
        total_organic_sites = 0
        school_sites_count = 0
        school_domains_found = []
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–º–µ–Ω –Ω–∞—à–µ–≥–æ —Å–∞–π—Ç–∞
        our_domain = get_campaign_domain(campaign_id, connection)
        log_print(f"üìå –ù–∞—à –¥–æ–º–µ–Ω –¥–ª—è –∫–∞–º–ø–∞–Ω–∏–∏ {campaign_id}: {our_domain or '–ù–ï –£–ö–ê–ó–ê–ù'}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤ —à–∫–æ–ª
        school_domains = get_school_domains(connection)
        log_print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–º–µ–Ω–æ–≤ —à–∫–æ–ª-–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤: {len(school_domains)}")
        if school_domains:
            log_print(f"   –î–æ–º–µ–Ω—ã —à–∫–æ–ª: {', '.join(list(school_domains)[:5])}")
        
        # –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        log_print("\nüîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –í–´–î–ê–ß–ò:")
        log_print("-" * 50)
        
        for idx, item in enumerate(items):
            item_type = item.get('type', '')
            position = item.get('rank_absolute', idx + 1)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï —ç–ª–µ–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω—ã
            item_parsed = {
                'position': position,
                'type': item_type,
                'domain': item.get('domain', ''),
                'url': item.get('url', ''),
                'title': (item.get('title', '') or '')[:100]
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫ –í–°–ï–ì–î–ê
            all_items_parsed.append(item_parsed)
            
            # –î–∞–ª–µ–µ –∏–¥–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ —Ç–∏–ø–∞–º...
            # –†–ï–ö–õ–ê–ú–ù–´–ï –ë–õ–û–ö–ò
            if item_type in ['paid', 'google_ads', 'shopping', 'commercial_units']:
                has_ads = True
                paid_results.append(item_parsed)
                log_print(f"   #{position} [–†–ï–ö–õ–ê–ú–ê] {item.get('domain', 'unknown')}")
                log_print(f"        URL: {(item.get('url', '') or '')[:80]}")
            
            # GOOGLE MAPS
            elif item_type in ['local_pack', 'maps', 'map', 'google_maps']:
                has_google_maps = True
                maps_results.append(item_parsed)
                log_print(f"   #{position} [–ö–ê–†–¢–´] Google Maps –±–ª–æ–∫")
                if item.get('items'):
                    log_print(f"        –ú–µ—Å—Ç –≤ –±–ª–æ–∫–µ: {len(item.get('items', []))}")
            
            # –û–†–ì–ê–ù–ò–ß–ï–°–ö–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´
            elif item_type == 'organic':
                total_organic_sites += 1
                
                url = (item.get('url', '') or '').lower()
                domain = (item.get('domain', '') or '').lower()
                title = item.get('title') or ''
                description = item.get('description') or ''
                
                # –û—á–∏—â–∞–µ–º –¥–æ–º–µ–Ω
                clean_domain = domain.replace('www.', '') if domain else ''
                
                organic_results.append({
                    'position': position,
                    'domain': clean_domain,
                    'title': title[:100] if title else '',
                    'url': url,
                    'description': description[:200] if description else ''
                })
                
                log_print(f"   #{position} [–û–†–ì–ê–ù–ò–ö–ê] {clean_domain}")
                log_print(f"        Title: {title[:60] if title else 'No title'}")
                log_print(f"        URL: {url[:80]}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—à —Å–∞–π—Ç
                if our_domain:
                    if our_domain in url or our_domain == clean_domain:
                        has_our_site = True
                        log_print(f"        ‚úÖ –≠–¢–û –ù–ê–® –°–ê–ô–¢!")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∞–π—Ç–æ–≤ —à–∫–æ–ª
                if clean_domain in school_domains:
                    school_sites_count += 1
                    school_domains_found.append(clean_domain)
                    has_school_sites = True
                    log_print(f"        üè´ –≠–¢–û –°–ê–ô–¢ –®–ö–û–õ–´-–ö–û–ù–ö–£–†–ï–ù–¢–ê!")
            
            # –î–†–£–ì–ò–ï –¢–ò–ü–´ - —Ç–æ–∂–µ –ª–æ–≥–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ
            else:
                log_print(f"   #{position} [{item_type.upper()}]")
                
                # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —Ç–∏–ø–∞–º
                if item_type == 'people_also_ask':
                    questions = item.get('items', [])
                    log_print(f"        –í–æ–ø—Ä–æ—Å–æ–≤: {len(questions)}")
                    if questions:
                        for q in questions[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –≤–æ–ø—Ä–æ—Å–∞
                            log_print(f"        - {q.get('title', '')[:60]}")
                            
                elif item_type == 'video':
                    videos = item.get('items', [])
                    log_print(f"        –í–∏–¥–µ–æ –±–ª–æ–∫ ({len(videos)} –≤–∏–¥–µ–æ)")
                    if videos:
                        for v in videos[:2]:  # –ü–µ—Ä–≤—ã–µ 2 –≤–∏–¥–µ–æ
                            log_print(f"        - {v.get('title', '')[:50]}")
                            
                elif item_type == 'ai_overview':
                    log_print(f"        AI Overview –±–ª–æ–∫")
                    text = item.get('text', '')
                    if text:
                        log_print(f"        –¢–µ–∫—Å—Ç: {text[:100]}...")
                        
                elif item_type == 'images':
                    log_print(f"        –ë–ª–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
                    
                elif item_type == 'related_searches':
                    searches = item.get('items', [])
                    log_print(f"        –ü–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã: {len(searches)}")
                    if searches:
                        for s in searches[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –∑–∞–ø—Ä–æ—Å–∞
                            log_print(f"        - {s.get('title', '')}")
                            
                elif item_type == 'people_also_search':
                    log_print(f"        –õ—é–¥–∏ —Ç–∞–∫–∂–µ –∏—â—É—Ç")
                    
                elif item_type == 'knowledge_graph':
                    log_print(f"        Knowledge Graph")
                    kg_title = item.get('title', '')
                    if kg_title:
                        log_print(f"        Title: {kg_title}")
                        
                elif item_type == 'featured_snippet':
                    log_print(f"        Featured Snippet")
                    domain = item.get('domain', '')
                    if domain:
                        log_print(f"        –ò—Å—Ç–æ—á–Ω–∏–∫: {domain}")
        
        log_print("-" * 50)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–Ω—Ç–µ–Ω—Ç–∞
        intent_type = '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π'
        school_percentage = 0
        
        if has_school_sites and total_organic_sites > 0:
            school_percentage = (school_sites_count / total_organic_sites) * 100
            log_print(f"\nüìä –ê–Ω–∞–ª–∏–∑ –∏–Ω—Ç–µ–Ω—Ç–∞:")
            log_print(f"   –û—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∞–π—Ç–æ–≤: {total_organic_sites}")
            log_print(f"   –°–∞–π—Ç–æ–≤ —à–∫–æ–ª: {school_sites_count}")
            log_print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —à–∫–æ–ª: {school_percentage:.1f}%")
            
            if school_percentage >= 60:
                intent_type = '–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π'
                log_print(f"   ‚Üí –ò–Ω—Ç–µ–Ω—Ç: –ö–û–ú–ú–ï–†–ß–ï–°–ö–ò–ô (—à–∫–æ–ª >= 60%)")
            else:
                log_print(f"   ‚Üí –ò–Ω—Ç–µ–Ω—Ç: –ò–ù–§–û–†–ú–ê–¶–ò–û–ù–ù–´–ô (—à–∫–æ–ª < 60%)")
        
        # –°–û–•–†–ê–ù–Ø–ï–ú –í –ë–î –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if keyword_id and connection:
            try:
                cursor = connection.cursor()
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
                import json
                raw_response_json = json.dumps({
                    'status_code': task.get('status_code'),
                    'items_count': items_count,
                    'se_results_count': se_results_count,
                    'item_types': item_types
                }, ensure_ascii=False)
                
                parsed_items_json = json.dumps({
                    'organic': organic_results,
                    'paid': paid_results,
                    'maps': maps_results,
                    'all_items': all_items_parsed
                }, ensure_ascii=False)
                
                # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞ –∏–∑ data
                request_data = task.get('data', {})
                if isinstance(request_data, list) and len(request_data) > 0:
                    request_params = request_data[0]
                else:
                    request_params = {}
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ç–∞–±–ª–∏—Ü—É serp_logs
                insert_query = """
                    INSERT INTO serp_logs (
                        keyword_id, keyword_text, location_code, language_code,
                        device, depth, total_items, organic_count, paid_count,
                        maps_count, shopping_count, has_ads, has_maps,
                        has_our_site, has_school_sites, intent_type,
                        school_percentage, cost, raw_response, parsed_items
                    ) VALUES (
                        %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                        %s, %s, %s, %s, %s, %s, %s
                    )
                """
                
                insert_values = (
                    keyword_id,
                    keyword_text or '',
                    request_params.get('location_code', 0),
                    request_params.get('language_code', ''),
                    request_params.get('device', 'desktop'),
                    request_params.get('depth', 0),
                    items_count,
                    total_organic_sites,
                    len(paid_results),
                    len(maps_results),
                    0,  # shopping_count
                    has_ads,
                    has_google_maps,
                    has_our_site,
                    has_school_sites,
                    intent_type,
                    school_percentage,
                    task.get('cost', 0),
                    raw_response_json,
                    parsed_items_json
                )
                
                cursor.execute(insert_query, insert_values)
                inserted_id = cursor.lastrowid
                connection.commit()
                cursor.close()
                
                log_print(f"üíæ SERP –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î (serp_logs), ID: {inserted_id}")
                
            except Exception as e:
                log_print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ serp_logs: {str(e)}")
                import traceback
                traceback.print_exc()
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å–≤–æ–¥–∫–∞
        log_print("\n" + "=" * 50)
        log_print(f"üìä –ò–¢–û–ì–ò SERP –ê–ù–ê–õ–ò–ó–ê:")
        log_print(f"   –û—Ä–≥–∞–Ω–∏–∫–∞: {total_organic_sites}")
        log_print(f"   –†–µ–∫–ª–∞–º–∞: {len(paid_results)}")
        log_print(f"   –ö–∞—Ä—Ç—ã: {len(maps_results)}")
        log_print(f"   –ù–∞—à —Å–∞–π—Ç: {'–î–ê' if has_our_site else '–ù–ï–¢'}")
        log_print(f"   –°–∞–π—Ç—ã —à–∫–æ–ª: {'–î–ê' if has_school_sites else '–ù–ï–¢'}")
        log_print(f"   –ò–Ω—Ç–µ–Ω—Ç: {intent_type}")
        log_print("=" * 50)
        
        return {
            'has_ads': has_ads,
            'has_school_sites': has_school_sites,
            'has_google_maps': has_google_maps,
            'has_our_site': has_our_site,
            'intent_type': intent_type,
            'stats': {
                'total_organic': total_organic_sites,
                'paid_count': len(paid_results),
                'maps_count': len(maps_results),
                'school_percentage': round(school_percentage, 1)
            }
        }
        
    except Exception as e:
        log_print(f"‚ùå Error parsing SERP response: {str(e)}")
        import traceback
        traceback.print_exc()
        return None
        
def get_campaign_domain(campaign_id: int, connection) -> str:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –¥–æ–º–µ–Ω —Å–∞–π—Ç–∞ –¥–ª—è –∫–∞–º–ø–∞–Ω–∏–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã campaign_sites
    """
    try:
        cursor = connection.cursor()
        cursor.execute("""
            SELECT domain 
            FROM campaign_sites 
            WHERE campaign_id = %s
        """, (campaign_id,))
        
        result = cursor.fetchone()
        cursor.close()
        
        if result and result['domain']:
            domain = result['domain'].lower()
            # –£–±–∏—Ä–∞–µ–º www. –µ—Å–ª–∏ –µ—Å—Ç—å
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain
        
        return None
        
    except Exception as e:
        log_print(f"‚ùå Error getting campaign domain: {e}")
        return None


def get_school_domains(connection) -> set:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤ —à–∫–æ–ª-–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –∏–∑ –ë–î
    """
    try:
        cursor = connection.cursor()
        cursor.execute("""
            SELECT domain 
            FROM school_sites 
            WHERE is_active = TRUE
        """)
        
        results = cursor.fetchall()
        cursor.close()
        
        # –°–æ–∑–¥–∞–µ–º set –¥–æ–º–µ–Ω–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        domains = set()
        for row in results:
            if row['domain']:
                domain = row['domain'].lower()
                # –£–±–∏—Ä–∞–µ–º www. –µ—Å–ª–∏ –µ—Å—Ç—å
                if domain.startswith('www.'):
                    domain = domain[4:]
                domains.add(domain)
        
        return domains
        
    except Exception as e:
        log_print(f"‚ö†Ô∏è Error getting school domains: {e}")
        # –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π set
        return set()